# Machine Learning AI for Chess

This folder contains the reinforcement learning (RL)-based AI logic used in the Chess project. It includes the training scripts, neural network architecture, simulation code, and utilities.

## ğŸ§© Overview

The AI is trained to play chess using a basic reinforcement learning approach based on self-play. It learns to evaluate board positions and choose moves that maximize its long-term win potential.

---

## ğŸ“ File Structure

- `network.py`  
  Defines the neural network architecture (`ChessNet`) used to evaluate board states.

- `trainer.py`  
  The training loop that performs self-play games and updates the model based on outcome rewards.

- `self_play.py`  
  Simulates chess games using a policy function and collects state/reward pairs for training.

- `utils.py`  
  Helper functions for converting board states to PyTorch tensors and encoding data.

- `chess_model.pt`  
  A saved PyTorch model (trained weights) produced after training.

---

## ğŸ§  How the AI Works

1. **Board Evaluation**  
   The AI learns a function that estimates how good a board position is for the current player.

2. **Self-Play**  
   The trainer uses random moves or the modelâ€™s current policy to simulate games, collect state-reward pairs, and train the network.

3. **Move Selection (During Gameplay)**  
   - All legal moves are simulated.
   - Each resulting board is evaluated using the model.
   - The move with the highest predicted value is chosen.

---

## ğŸš€ Training the AI

To train a model from scratch:

```bash
python3 -m ml.trainer
